{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classwork 05\n",
    "\n",
    "YourNameHere\n",
    "\n",
    "DateHere\n",
    "\n",
    "## Defining Mathematical Functions\n",
    "\n",
    "The following code shows features of numpy for rapidly implementing discrete approximations of mathematical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gaussian(x):\n",
    "    \"\"\"gaussian(x)\n",
    "    \n",
    "    Normalized Gaussian function, also known as a normal distribution, or a bell curve.\n",
    "    \"\"\"\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp(-x**2/2)\n",
    "\n",
    "def lorentzian(x):\n",
    "    \"\"\"lorentzian(x)\n",
    "    \n",
    "    Normalized Lorentzian function, also known as a Cauchy distribution, or a resonance linewidth.\n",
    "    \"\"\"\n",
    "    return (1/np.pi)/(1 + x**2)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"sigmoid(x)\n",
    "    \n",
    "    Sigmoid function, used to simulate neuron activation in neural networks.\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sinc(x):\n",
    "    \"\"\"sinc(x)\n",
    "    \n",
    "    Sinc function, appears in single-slit diffraction, and is Fourier transform of a tophat function.\n",
    "    \"\"\"\n",
    "    # Avoids division by zero by defaulting to the value 1\n",
    "    return np.divide(np.sin(x), x, out=np.ones_like(x), where=(x!=0))\n",
    "\n",
    "def raisedcosine(x):\n",
    "    \"\"\"raisedcosine(x)\n",
    "    \n",
    "    Raised cosine distribution, has compact support but similar to bell curve.\n",
    "    \"\"\"\n",
    "    # Efficient conditional evaluation across array\n",
    "    return np.where(np.abs(x) < np.pi, (1 + np.cos(x))/(2*np.pi), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that the python function definitions are type agnostic: the parameter `x` could be any type, and the code will run provided that the expressions inside the function are compatible with that type. This type-agnosticism of python is often called \"duck typing\", since if it walks like a duck, and quacks like a duck, python will think it is a duck. For the cases above, functions that rely only on array broadcasting and vectorization will have the operations will work correctly when `x` is a float, or when `x` in an array as floats. This is one of the main reasons that broadcasting and vectorization are given no special syntax in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18493728096330531, 0.125437376333461, 0.7755640142690734]"
      ]
     },
     "execution_count": 3,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(1.24) for f in [gaussian, lorentzian, sigmoid]]  # evaluation on a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.24197072,  0.39894228,  0.24197072]),\n",
       " array([ 0.15915494,  0.31830989,  0.15915494]),\n",
       " array([ 0.26894142,  0.5       ,  0.73105858])]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(np.linspace(-1,1,3)) for f in [gaussian, lorentzian, sigmoid]] # evaluation on an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The remaining two functions use features specific to numpy arrays, so will autoconvert a float input to an array output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(0.7627290318141443), array(0.2108478772582078)]"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f(1.24) for f in [sinc, raisedcosine]] # numpy specialized evaluation on a float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make sure you understand the concepts of broadcasting and vectorization for arrays. Explain those concepts in your own words below, and use code examples to illustrate your descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5  0.5 -0.5 -0.5]\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting is when two arrays operated on and the smaller array is broadcast across the larger one. Example: \n",
    "array1 = np.array([1,1,-1,-1])\n",
    "array2 = np.array([0.5])\n",
    "array3 = array1*array2\n",
    "print (array3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.71828183   7.3890561   20.08553692   7.3890561 ]\n"
     ]
    }
   ],
   "source": [
    "# Vectorization involves applying a function to all elements in an array and returning an array populated with the modified values. For example:\n",
    "narray = np.array([1,2,3,2])\n",
    "def exp(x):\n",
    "    return np.exp(x)\n",
    "fx = np.vectorize(exp) \n",
    "print(fx(narray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lazy Plotting with Dataframes\n",
    "\n",
    "For quick plots, it is convenient to neatly package all function range data together with their common domain data. Pandas dataframes are ideally suited for such data organization. Dataframes also provide a simple plot interface to quickly generate plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def make_plots(a=-10,b=10,n=1000):\n",
    "    # Generate n domain points equally spaced to cover the interval [a,b]\n",
    "    x = np.linspace(a,b,n)\n",
    "    \n",
    "    # Collect function range points corresponding to domain points\n",
    "    fs = pd.DataFrame({\"x\":x\n",
    "                     ,\"gaussian\":gaussian(x)\n",
    "                     ,\"lorentzian\":lorentzian(x)\n",
    "                     ,\"sigmoid\":sigmoid(x)\n",
    "                     ,\"sinc\":sinc(x)\n",
    "                     ,\"raisedcosine\":raisedcosine(x)\n",
    "                     })\n",
    "    \n",
    "    # Plot all range points with respect to same domain points x\n",
    "    fs.plot(x='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "c16d97c2b548b2ca48e2481aa5068c19fd261de3"
     },
     "metadata": {
      "image/png": {
       "height": 426,
       "width": 726
      }
     }
    }
   ],
   "source": [
    "make_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "72be85971c682321bff95b0797d259886becfb93"
     },
     "metadata": {
      "image/png": {
       "height": 426,
       "width": 724
      }
     }
    }
   ],
   "source": [
    "make_plots(a=-100,b=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "5235811e41003a7816eadb5c98f180a64461af6f"
     },
     "metadata": {
      "image/png": {
       "height": 426,
       "width": 718
      }
     }
    }
   ],
   "source": [
    "make_plots(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting with Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Use `matplotlib.pyplot` to generate a plot comparing the Gaussian function, Lorentzian function, and raised cosine function in more detail. Plot the Gaussian in blue, the Lorentzian in red, and the raised cosine in green. Make the Gaussian solid, the Lorentzian dashed, and the raised cosine dotted. Create a legend that labels each curve. Resize the tickmarks to be double the default size. Label the x axis as \"x\" and double the default font size. Create a plot title of \"Distribution comparison\". Annotate the plot with a point on each curve at $x=\\pi$, with an arrow pointing to one of the points with a label of $\\pi$.\n",
    "\n",
    "After you handle the 1d case, create separate 2d plots of each function by interpreting the \"x\" value of each function as the radius away from the origin in a 3d plane (so that each 2d function is symmetric under rotations around the origin in the plane).\n",
    "\n",
    "The following resources may be helpful:\n",
    "  - https://www.labri.fr/perso/nrougier/teaching/matplotlib/\n",
    "  - http://matplotlib.org/gallery.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "f4ddf5971dc798d8944f7acc3e6b2ac0736123f0"
     },
     "metadata": {
      "image/png": {
       "height": 450,
       "width": 715
      }
     }
    }
   ],
   "source": [
    "X = [f(np.linspace(-10,10,1000)) for f in [gaussian, lorentzian, raisedcosine]]\n",
    "G = X[0]\n",
    "L = X[1]\n",
    "R = X[2]\n",
    "plt.plot(np.linspace(-10,10,1000),G,\"b-\")\n",
    "plt.plot(np.linspace(-10,10,1000),L,\"r--\")\n",
    "plt.plot(np.linspace(-10,10,1000),R,\"g:\")\n",
    "plt.xlabel('x', fontsize = 15)\n",
    "plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi],[r'$-\\pi$', r'$-\\pi/2$', r'$0$', r'$+\\pi/2$', r'$+\\pi$'],fontsize = 15)\n",
    "plt.annotate(r'$G(\\pi)$',\n",
    "             xy=(np.pi, gaussian(np.pi)), xycoords='data',\n",
    "             xytext=(+10, +30), textcoords='offset points', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
    "plt.annotate(r'$L(\\pi)$',\n",
    "             xy=(np.pi, lorentzian(np.pi)), xycoords='data',\n",
    "             xytext=(+10, +30), textcoords='offset points', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
    "plt.annotate(r'$RC(\\pi)$',\n",
    "             xy=(np.pi, raisedcosine(np.pi)), xycoords='data',\n",
    "             xytext=(+50, +30), textcoords='offset points', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
    "plt.title('Distribution comparison')\n",
    "plt.legend(['Gaussian','Lorentzian','Raised Cosine'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plotting with Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Seaborn is a statistical plotting extension to Matplotlib that uses nicer visual defaults for common data-processing tasks. Consider the following code fragment that generates a set of random points sampled from a normalized Gaussian distribution and generates a histogram of the data. The blue curve is the estimated continuous distribution function that is consistent with the sampled data. The red curve is the Gaussian function defined above. Show by increasing the parameter `n` that collecting more samples improves the estimate to converge to the actual Gaussian being used to generate the data. How many samples are required before the distribution convincingly converges? Answer: about >10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gaussian_sample(n):\n",
    "    # Generate n random normally-distributed floats\n",
    "    data = np.random.randn(n)\n",
    "    # Create domain of points for plotting\n",
    "    x = np.linspace(-4,4,100)\n",
    "    # Plot\n",
    "    plt.figure(1)\n",
    "    plt.title(\"Gaussian sampling\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.plot(x,gaussian(x),label=\"gaussian\",color=\"red\")\n",
    "    # Use seaborn to generate histogram and estimate distribution\n",
    "    sb.distplot(data,label=\"data\",color=\"blue\",kde_kws={\"label\":\"estimate\"})\n",
    "    # Label curves\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "84ba25a7effba1507a2ecd8b6fe116bc1005865d"
     },
     "metadata": {
      "image/png": {
       "height": 440,
       "width": 715
      }
     }
    }
   ],
   "source": [
    "gaussian_sample(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Repeat the above analysis for the Lorentzian distribution (see `numpy.random.standard_cauchy` for sampling Lorentzian-distributed random numbers). How many samples do you need to show convergence to the distribution? Speculate why there is a difference between the Gaussian and Lorentzian cases. Answer: 100 samples is ideal; no more, no less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Lorentzian\n",
    "def lorentzian_sample(n):\n",
    "    # Generate n random normally-distributed floats\n",
    "    data = np.random.standard_cauchy(n)\n",
    "    # Create domain of points for plotting\n",
    "    x = np.linspace(-40,40,100)\n",
    "    # Plot\n",
    "    plt.figure(1)\n",
    "    plt.title(\"Lorentzian sampling\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.plot(x,lorentzian(x),label=\"lorentzian\",color=\"red\")\n",
    "    # Use seaborn to generate histogram and estimate distribution\n",
    "    sb.distplot(data,label=\"data\",color=\"blue\",kde_kws={\"label\":\"estimate\"})\n",
    "    # Label curves\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "02443a67df7d7015f491eaff89bed419ef2dceae"
     },
     "metadata": {
      "image/png": {
       "height": 440,
       "width": 715
      }
     }
    }
   ],
   "source": [
    "lorentzian_sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Seaborn is extremely powerful for manipulating statistics and processing data points. For more examples see:\n",
    "  - https://seaborn.pydata.org/examples/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}